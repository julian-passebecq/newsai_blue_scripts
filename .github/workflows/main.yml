name: Update Data

on:
  schedule:
    - cron: '0 0 * * *'  # Runs at midnight UTC every day
  workflow_dispatch:

jobs:
  update-data:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Fetch all history for all tags and branches

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install pandas requests advertools

      # Run Python scripts
      - name: Run Sitemap Extraction
        run: python site.py
        working-directory: newsai_script-main

      - name: Run YouTube Videos Fetching
        run: python youtube.py
        working-directory: newsai_script-main

      - name: Run Concatenation
        run: python concatenation.py
        working-directory: newsai_script-main

      # Move the sitemap output file to the data directory, then copy it to the public directory
      - name: Update sitemap.csv in the public directory
        run: |
          cp newsai_script-main/data/sitemap.csv public/sitemap.csv

      # Ensure the local repository is in sync with the remote one
      - name: Reset local changes to match remote
        run: |
          git fetch origin
          git reset --hard origin/main

      # Commit and push sitemap.csv
      - name: Commit and Push sitemap.csv
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add public/sitemap.csv
          git commit -m "Automated update of sitemap.csv"
          git push --force
